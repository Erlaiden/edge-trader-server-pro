#pragma once
#include "server_utils.h"

static void register_health_routes(httplib::Server& srv){
  srv.Get("/health", [](const httplib::Request&, httplib::Response& res){
    REQ_HEALTH.fetch_add(1, std::memory_order_relaxed);
    long long now_ms = (long long)time(nullptr)*1000;
    json j{
      {"ok",true},
      {"ts", now_ms},
      {"uptime_s", (now_ms - PROCESS_START_MS)/1000},
      {"model_build_ts_ms", MODEL_BUILD_TS.load()},
      {"last_train_ts_ms",  LAST_TRAIN_TS.load()},
      {"last_infer_ts_ms",  LAST_INFER_TS.load()},
      {"data_rows", {{"15",DATA_ROWS_15.load()},{"60",DATA_ROWS_60.load()},{"240",DATA_ROWS_240.load()},{"1440",DATA_ROWS_1440.load()}}}
    };
    res.set_content(j.dump(), "application/json");
  });

  srv.Get("/api/health/ai", [](const httplib::Request& req, httplib::Response& res){
    std::string symbol   = qp(req, "symbol", "BTCUSDT");
    std::string interval = qp(req, "interval", "15");

    json h15   = data_health_report(symbol, "15");
    json h60   = data_health_report(symbol, "60");
    json h240  = data_health_report(symbol, "240");
    json h1440 = data_health_report(symbol, "1440");

    json model_info = json::object();
    const std::string path = "cache/models/" + symbol + "_" + interval + "_ppo_pro.json";
    { std::ifstream f(path); if (f) { f >> model_info; model_info["ok"]=true; model_info["path"]=path; model_info["mode"]="pro"; }
      else model_info = json{{"ok",false},{"path",path}}; }

    if (model_info.value("ok", false)) {
      if (CV_FOLDS.load()==0) {
        unsigned long long cvf = (unsigned long long)model_info.value("cv_folds", 0);
        unsigned long long cve = (unsigned long long)model_info.value("cv_effective_folds", cvf);
        if (cvf>0){
          CV_FOLDS.store(cvf, std::memory_order_relaxed);
          CV_EFFECTIVE_FOLDS.store(cve, std::memory_order_relaxed);
          auto is_m = model_info.value("is", json::object());
          auto oos_m= model_info.value("oos", json::object());
          CV_IS_SHARPE.store(is_m.value("sharpe", 0.0), std::memory_order_relaxed);
          CV_OOS_SHARPE.store(oos_m.value("sharpe", 0.0), std::memory_order_relaxed);
          CV_IS_EXPEC.store(is_m.value("expectancy", 0.0), std::memory_order_relaxed);
          CV_OOS_EXPEC.store(oos_m.value("expectancy", 0.0), std::memory_order_relaxed);
          CV_OOS_DD_MAX.store(oos_m.value("drawdown_max", 0.0), std::memory_order_relaxed);
        }
      }
      if (TRAIN_ROWS_USED.load()==0) TRAIN_ROWS_USED.store((unsigned long long)model_info.value("train_rows_used", 0), std::memory_order_relaxed);
      if (MODEL_BUILD_TS.load()==0)  MODEL_BUILD_TS.store((long long)model_info.value("build_ts", 0LL), std::memory_order_relaxed);
      MODEL_BEST_THR.store(model_info.value("best_thr", 0.0), std::memory_order_relaxed);
      MODEL_MA_LEN.store((long long)model_info.value("ma_len", 12), std::memory_order_relaxed);
    }

    long long now_ms = (long long)time(nullptr)*1000;
    long long ts_max_15 = (long long)h15.value("ts_max", 0LL);
    long long fresh_ms = (ts_max_15>0) ? std::max(0LL, now_ms - ts_max_15) : 0LL;
    DATA_FRESH_MS.store(fresh_ms, std::memory_order_relaxed);

    json cv{
      {"folds", (unsigned long long)CV_FOLDS.load()},
      {"effective_folds", (unsigned long long)CV_EFFECTIVE_FOLDS.load()},
      {"is",    {{"sharpe", (double)CV_IS_SHARPE.load()}, {"expectancy",(double)CV_IS_EXPEC.load()}}},
      {"oos",   {{"sharpe", (double)CV_OOS_SHARPE.load()}, {"expectancy",(double)CV_OOS_EXPEC.load()}, {"drawdown_max",(double)CV_OOS_DD_MAX.load()}}}
    };

    json out{
      {"ok", true},
      {"ts", now_ms},
      {"data", {{"15",h15},{"60",h60},{"240",h240},{"1440",h1440}}},
      {"data_fresh_ms", fresh_ms},
      {"model", model_info},
      {"cv", cv},
      {"model_thr", (double)MODEL_BEST_THR.load()},
      {"model_ma_len", (long long)MODEL_MA_LEN.load()}
    };
    res.set_content(out.dump(2), "application/json");
  });
}
